# -*- coding: utf-8 -*-
"""DataStandardization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WDqtf7M-NVNj79RIQ9SvVHQXZArHeveI

Data Standardization:<br>
the process of standardizing data into common format and common range
"""

import numpy as np
import pandas as pd
import sklearn.datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# loading the datasets
dataset = sklearn.datasets.load_breast_cancer()

print(dataset)

# loading the data into pandas data frame
df = pd.DataFrame(dataset.data, columns = dataset.feature_names)

df.head()

df.shape

X = df
Y = dataset.target

print(X)

print(Y)

"""Splitting the data into training data and testing data:"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 3)

# outlier values are the abnormal values which will occur when we use the data without splitting
print(X.shape, X_train.shape, X_test.shape)

print(dataset.data.std())

#sklearn.preprocessing.StandardScaler is a data preprocessing tool in scikit-learn that standardizes features by removing the mean and scaling to unit variance.

#In other words, it transforms your dataset so that each feature has:

#Mean = 0

#Standard deviation = 1

scaler = StandardScaler()

scaler.fit(X_train)

X_train_standardized = scaler.transform(X_train)

print(X_train_standardized)

X_test_standardized = scaler.transform(X_test)

print(X_test_standardized.std())

print(X_train_standardized.std())

